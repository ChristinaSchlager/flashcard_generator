%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english,openany,oneside]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Table of Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{Flashcard Generator}
\date{Sep 20, 2024}
\release{1.0.0}
\author{Christina Schlager}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{Data Preparation}
\label{\detokenize{data_preparation:data-preparation}}\label{\detokenize{data_preparation::doc}}
\sphinxAtStartPar
This section covers functions related to preparing data for the RAG pipeline.
\index{module@\spxentry{module}!tools.pipeline@\spxentry{tools.pipeline}}\index{tools.pipeline@\spxentry{tools.pipeline}!module@\spxentry{module}}\index{load\_wikipedia\_dataset() (in module tools.pipeline)@\spxentry{load\_wikipedia\_dataset()}\spxextra{in module tools.pipeline}}\phantomsection\label{\detokenize{data_preparation:module-tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data_preparation:tools.pipeline.load_wikipedia_dataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{load\_wikipedia\_dataset}}}{\sphinxparam{\DUrole{n}{language}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}simple\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{date}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}20220301\textquotesingle{}}}}{{ $\rightarrow$ Dataset}}
\pysigstopsignatures
\sphinxAtStartPar
Load the Wikipedia dataset from the Hugging Face Hub. This function loads the dataset
specified by language and date.

\sphinxAtStartPar
Hugging Face Dataset URL: \sphinxurl{https://huggingface.co/datasets/wikipedia}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{language}} \textendash{} Language version of Wikipedia to load. Defaults to ‘simple’ for Simple English.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{date}} \textendash{} The snapshot date of the Wikipedia dataset to load. Format: YYYYMMDD. Defaults to “20220301”.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A dataset object that allows accessing the data as required.

\end{description}\end{quote}

\end{fulllineitems}

\index{process\_documents() (in module tools.pipeline)@\spxentry{process\_documents()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data_preparation:tools.pipeline.process_documents}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{process\_documents}}}{\sphinxparam{\DUrole{n}{data}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{Dict\DUrole{p}{{[}}str\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{chunk\_size}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{int}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{5000}}\sphinxparamcomma \sphinxparam{\DUrole{n}{chunk\_overlap}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{int}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{100}}\sphinxparamcomma \sphinxparam{\DUrole{n}{min\_valid\_length}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{int}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{200}}}{{ $\rightarrow$ Tuple\DUrole{p}{{[}}List\DUrole{p}{{[}}Any\DUrole{p}{{]}}\DUrole{p}{,}\DUrole{w}{ }List\DUrole{p}{{[}}int\DUrole{p}{{]}}\DUrole{p}{,}\DUrole{w}{ }int\DUrole{p}{,}\DUrole{w}{ }int\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Process a dataset of documents by splitting each document into chunks, filtering these chunks based
on a minimum valid length, and annotating them with metadata.

\sphinxAtStartPar
This function uses a RecursiveCharacterTextSplitter to break down documents into manageable chunks. 
Chunks that meet the minimum length requirement are kept and annotated with metadata from the original
document. The function then returns a list of valid chunks and statistics about the processing.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data}} \textendash{} A dictionary containing a ‘train’ key with a list of document dictionaries. Each document
should have ‘text’, ‘id’, ‘url’, and ‘title’ keys.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{chunk\_size}} \textendash{} The size of each chunk in characters.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{chunk\_overlap}} \textendash{} The number of characters to overlap between chunks.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_valid\_length}} \textendash{} The minimum number of characters a chunk must have to be considered valid.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A tuple containing four elements:
\sphinxhyphen{} A list of valid chunks, where each chunk is an object with ‘page\_content’ and ‘metadata’, which contains ID, url, and title.
\sphinxhyphen{} A list containing the count of chunks created from each document.
\sphinxhyphen{} Total number of chunks created across all documents.
\sphinxhyphen{} Total number of valid chunks that met the length requirement.

\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Data Storage}
\label{\detokenize{data_storage:data-storage}}\label{\detokenize{data_storage::doc}}
\sphinxAtStartPar
This section explains how data is stored in ChromaDB for efficient retrieval and processing.
\index{module@\spxentry{module}!tools.pipeline@\spxentry{tools.pipeline}}\index{tools.pipeline@\spxentry{tools.pipeline}!module@\spxentry{module}}\index{load\_vectorstore\_nomic() (in module tools.pipeline)@\spxentry{load\_vectorstore\_nomic()}\spxextra{in module tools.pipeline}}\phantomsection\label{\detokenize{data_storage:module-tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data_storage:tools.pipeline.load_vectorstore_nomic}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{load\_vectorstore\_nomic}}}{\sphinxparam{\DUrole{n}{path}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}./chroma\_db\_nomic\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{collection\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}opensource\_rag\_wikipedia\textquotesingle{}}}}{{ $\rightarrow$ Tuple\DUrole{p}{{[}}Chroma\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Loads a vector store configured to use the Nomic embeddings with a specified collection.

\sphinxAtStartPar
This function initializes an embeddings object and a persistent client, retrieves the specified
collection from the database, and finally initializes and returns a \sphinxtitleref{Chroma} vector store object
configured with the Nomic embeddings.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} The file path where the vector store data is located. Defaults to “./chroma\_db\_nomic”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{collection}} \textendash{} The name of the collection to be used in the vector store.

\end{itemize}

\end{description}\end{quote}

\sphinxAtStartPar
Defaults to “opensource\_rag\_wikipedia”.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
A configured instance of the \sphinxtitleref{Chroma} vector store.

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_vectorstore\_openai() (in module tools.pipeline)@\spxentry{load\_vectorstore\_openai()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data_storage:tools.pipeline.load_vectorstore_openai}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{load\_vectorstore\_openai}}}{\sphinxparam{\DUrole{n}{path}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}./chroma\_db\_openai\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{collection\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}openai\_rag\_chroma\_wikipedia\textquotesingle{}}}}{{ $\rightarrow$ Tuple\DUrole{p}{{[}}Chroma\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Loads a vector store configured to use OpenAI embeddings with a specified collection.

\sphinxAtStartPar
This function initializes an OpenAI embeddings object and a persistent client, retrieves the specified
collection from the database, and initializes a \sphinxtitleref{Chroma} vector store object configured with
the OpenAI embeddings.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} The file path where the vector store data is located. Defaults to “./chroma\_db\_openai”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{collection\_name}} \textendash{} The name of the collection to be used in the vector store.
Defaults to “openai\_rag\_chroma\_wikipedia”.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A configured instance of the \sphinxtitleref{Chroma} vector store containing the documents and the \sphinxtitleref{OpenAIEmbeddings} used.

\end{description}\end{quote}

\end{fulllineitems}

\index{setup\_vectorstore\_nomic() (in module tools.pipeline)@\spxentry{setup\_vectorstore\_nomic()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data_storage:tools.pipeline.setup_vectorstore_nomic}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{setup\_vectorstore\_nomic}}}{\sphinxparam{\DUrole{n}{texts}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{List\DUrole{p}{{[}}Any\DUrole{p}{{]}}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{path}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}./chroma\_db\_nomic\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{collection\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}opensource\_rag\_wikipedia\textquotesingle{}}}}{{ $\rightarrow$ Tuple\DUrole{p}{{[}}Chroma\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Sets up a vector store using Nomic embeddings (model “nomic\sphinxhyphen{}embed\sphinxhyphen{}text\sphinxhyphen{}v1.5”) with documents provided. 
The function initializes Nomic embeddings, sets up a persistent client, ensures the collection 
exists (or creates it),  and populates a vector store with the documents.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{texts}} \textendash{} A list of documents (texts) to be stored in the vector store.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} The file path where the vector store data will be located. Defaults to “./chroma\_db\_nomic”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{collection}} \textendash{} The name of the collection to be used or created in the vector store.
Defaults to “opensource\_rag\_wikipedia”.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A configured instance of the \sphinxtitleref{Chroma} vector store containing the documents and ‘Nomic Embeddings’ used.

\end{description}\end{quote}

\end{fulllineitems}

\index{setup\_vectorstore\_openai() (in module tools.pipeline)@\spxentry{setup\_vectorstore\_openai()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data_storage:tools.pipeline.setup_vectorstore_openai}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{setup\_vectorstore\_openai}}}{\sphinxparam{\DUrole{n}{texts}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{List\DUrole{p}{{[}}Any\DUrole{p}{{]}}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{path}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}./chroma\_db\_openai\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{collection\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}openai\_rag\_chroma\_wikipedia\textquotesingle{}}}}{{ $\rightarrow$ Tuple\DUrole{p}{{[}}Chroma\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Sets up a vector store using OpenAI embeddings (model “text\sphinxhyphen{}embedding\sphinxhyphen{}3\sphinxhyphen{}large”) with the provided documents. The function initializes
OpenAI embeddings, sets up a persistent client, checks for the existence of the specified collection
(or creates it), and populates a vector store with the documents.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{texts}} \textendash{} A list of documents (texts) to be stored in the vector store.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} The file path where the vector store data will be located. Defaults to “./chroma\_db\_openai”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{collection\_name}} \textendash{} The name of the collection to be used or created in the vector store. 
Defaults to “openai\_rag\_chroma\_wikipedia”.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A tuple containing a configured instance of the \sphinxtitleref{Chroma} vector store and the \sphinxtitleref{OpenAIEmbeddings} used.

\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Retriever}
\label{\detokenize{retriever:retriever}}\label{\detokenize{retriever::doc}}
\sphinxAtStartPar
This section outlines the functionality of the retriever component, responsible for fetching relevant embeddings based on query vectors.
\index{module@\spxentry{module}!tools.pipeline@\spxentry{tools.pipeline}}\index{tools.pipeline@\spxentry{tools.pipeline}!module@\spxentry{module}}\index{format\_documents() (in module tools.pipeline)@\spxentry{format\_documents()}\spxextra{in module tools.pipeline}}\phantomsection\label{\detokenize{retriever:module-tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{retriever:tools.pipeline.format_documents}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{format\_documents}}}{\sphinxparam{\DUrole{n}{docs}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{List\DUrole{p}{{[}}Any\DUrole{p}{{]}}}}}{{ $\rightarrow$ List\DUrole{p}{{[}}Dict\DUrole{p}{{[}}str\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Formats a list of document objects into a standardized dictionary format.

\sphinxAtStartPar
This function iterates through each document in the provided list, extracting relevant metadata namely, page content, ID, title, and source (URL).
Each document is then transformed into a dictionary with keys for ‘context’, ‘id’, ‘title’, and ‘source’, based on the respective properties and metadata from the document objects.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{docs}} \textendash{} A list of document objects, each containing content and metadata.

\sphinxlineitem{Returns}
\sphinxAtStartPar
A list of dictionaries where each dictionary represents a document with formatted data.

\end{description}\end{quote}

\end{fulllineitems}

\index{retrieve\_documents() (in module tools.pipeline)@\spxentry{retrieve\_documents()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{retriever:tools.pipeline.retrieve_documents}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{retrieve\_documents}}}{\sphinxparam{\DUrole{n}{topic}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{vectorstore}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{Chroma}}\sphinxparamcomma \sphinxparam{\DUrole{n}{threshold}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{float}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{0.5}}}{{ $\rightarrow$ List\DUrole{p}{{[}}Any\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Retrieves documents from the vector store based on a similarity score threshold.

\sphinxAtStartPar
This function initializes a retriever with the specified threshold for similarity scoring, using the ‘similarity\_score\_threshold’ search type.
It then invokes the retriever with a given topic to fetch documents that meet or exceed the specified similarity score threshold.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{topic}} \textendash{} The topic query as a string which is used to retrieve relevant documents.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{vectorstore}} \textendash{} The vector store instance which contains the document embeddings and provides the retrieval mechanism.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{threshold}} \textendash{} The minimum similarity score threshold. Documents with a similarity score above this threshold will be considered relevant.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Returns a list of documents or relevant entries that match the topic based on the specified similarity score threshold.

\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Generation}
\label{\detokenize{generation:generation}}\label{\detokenize{generation::doc}}
\sphinxAtStartPar
This section details the generation component, which focuses on producing question\sphinxhyphen{}answer pairs based on the retrieved documents.
\index{module@\spxentry{module}!tools.pipeline@\spxentry{tools.pipeline}}\index{tools.pipeline@\spxentry{tools.pipeline}!module@\spxentry{module}}\index{calculate\_num\_pairs() (in module tools.pipeline)@\spxentry{calculate\_num\_pairs()}\spxextra{in module tools.pipeline}}\phantomsection\label{\detokenize{generation:module-tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generation:tools.pipeline.calculate_num_pairs}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{calculate\_num\_pairs}}}{\sphinxparam{\DUrole{n}{text}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}}{{ $\rightarrow$ int}}
\pysigstopsignatures
\sphinxAtStartPar
Calculates the number of sections a text can be divided into using the \sphinxtitleref{split\_text\_into\_sections} function.

\sphinxAtStartPar
This function first divides the text into sections based on predefined criteria in \sphinxtitleref{split\_text\_into\_sections}.
It then calculates the number of these sections (pairs), returning the total count.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{text}} \textendash{} The text for which to calculate the number of dividable sections.

\sphinxlineitem{Returns}
\sphinxAtStartPar
The number of sections into which the text was divided.

\end{description}\end{quote}

\end{fulllineitems}

\index{generate\_question\_answer\_pairs\_open\_ai\_json() (in module tools.pipeline)@\spxentry{generate\_question\_answer\_pairs\_open\_ai\_json()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generation:tools.pipeline.generate_question_answer_pairs_open_ai_json}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{generate\_question\_answer\_pairs\_open\_ai\_json}}}{\sphinxparam{\DUrole{n}{topic}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{vectorstore}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{Chroma}}\sphinxparamcomma \sphinxparam{\DUrole{n}{threshold}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{float}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{0.5}}}{{ $\rightarrow$ str}}
\pysigstopsignatures
\sphinxAtStartPar
Generates unique question\sphinxhyphen{}answer pairs from documents retrieved based on a topic.

\sphinxAtStartPar
This function first retrieves documents related to the specified topic with a similarity score above the given threshold.
It then formats these documents and splits them into smaller sections suitable for generating question\sphinxhyphen{}answer pairs.
Each section is processed to produce unique and contextually relevant question\sphinxhyphen{}answer pairs, using the model
‘gpt\sphinxhyphen{}4\sphinxhyphen{}turbo’ via the OpenAI API.
\begin{description}
\sphinxlineitem{\sphinxstylestrong{Dependencies}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{OpenAI API}: Used to generate question\sphinxhyphen{}answer pairs using a model\sphinxhyphen{}based approach.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Model}: ‘gpt\sphinxhyphen{}4\sphinxhyphen{}turbo’. This model is specified for its ability to generate detailed and contextually
accurate question\sphinxhyphen{}answer pairs.

\end{itemize}

\end{description}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{topic}} \textendash{} The topic query to fetch related documents.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{vectorstore}} \textendash{} The vector store instance used to retrieve document embeddings.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{threshold}} \textendash{} The similarity score threshold for document retrieval. Defaults to 0.5.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A JSON string containing a list of unique question\sphinxhyphen{}answer pairs generated from the documents.

\end{description}\end{quote}

\end{fulllineitems}

\index{generate\_question\_answer\_pairs\_open\_source\_json() (in module tools.pipeline)@\spxentry{generate\_question\_answer\_pairs\_open\_source\_json()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generation:tools.pipeline.generate_question_answer_pairs_open_source_json}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{generate\_question\_answer\_pairs\_open\_source\_json}}}{\sphinxparam{\DUrole{n}{topic}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{vectorstore}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{Chroma}}\sphinxparamcomma \sphinxparam{\DUrole{n}{threshold}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{float}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{0.5}}}{{ $\rightarrow$ str}}
\pysigstopsignatures
\sphinxAtStartPar
Generates unique question\sphinxhyphen{}answer pairs from documents retrieved based on a topic.

\sphinxAtStartPar
This function first retrieves documents related to the specified topic with a similarity score above the given threshold.
It then formats these documents and splits them into smaller sections suitable for generating question\sphinxhyphen{}answer pairs.
Each section is processed to produce unique and contextually relevant question\sphinxhyphen{}answer pairs, using the model
‘meta\sphinxhyphen{}llama/Meta\sphinxhyphen{}Llama\sphinxhyphen{}3.1\sphinxhyphen{}70B\sphinxhyphen{}Instruct\sphinxhyphen{}Turbo’ via the Together API.
\begin{description}
\sphinxlineitem{\sphinxstylestrong{Dependencies}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Together API}: Used to generate question\sphinxhyphen{}answer pairs using a model\sphinxhyphen{}based approach.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Model}: ‘meta\sphinxhyphen{}llama/Meta\sphinxhyphen{}Llama\sphinxhyphen{}3.1\sphinxhyphen{}70B\sphinxhyphen{}Instruct\sphinxhyphen{}Turbo’. This model is specified to generate question\sphinxhyphen{}answer
pairs that are unique and tailored to the educational content based on the document’s context.

\end{itemize}

\end{description}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{topic}} \textendash{} The topic query to fetch related documents.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{vectorstore}} \textendash{} The vector store instance used to retrieve document embeddings.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{threshold}} \textendash{} The similarity score threshold for document retrieval. Defaults to 0.5.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A JSON string containing a list of unique question\sphinxhyphen{}answer pairs generated from the documents.

\end{description}\end{quote}

\end{fulllineitems}

\index{split\_text\_into\_sections() (in module tools.pipeline)@\spxentry{split\_text\_into\_sections()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generation:tools.pipeline.split_text_into_sections}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{split\_text\_into\_sections}}}{\sphinxparam{\DUrole{n}{text}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{max\_length}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{int}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{150}}\sphinxparamcomma \sphinxparam{\DUrole{n}{min\_length}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{int}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{50}}}{{ $\rightarrow$ List\DUrole{p}{{[}}str\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Splits a given text into sections based on specified maximum and minimum lengths.

\sphinxAtStartPar
The function divides the input text into paragraphs, and sequentially adds paragraphs
to a current section until adding another paragraph would exceed the maximum length.
If the current section meets the minimum length requirement, it is saved as a separate
section. This continues until all paragraphs are processed.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{text}} \textendash{} The text to be split into sections.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_length}} \textendash{} The maximum length of each section in characters, defaults to 150.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_length}} \textendash{} The minimum length a section must have to be considered valid, defaults to 50.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A list of text sections that meet the length requirements.

\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Evaluation}
\label{\detokenize{evaluation:evaluation}}\label{\detokenize{evaluation::doc}}
\sphinxAtStartPar
This section covers the evaluation methods for the RAG pipeline, utilizing Ragas, DeepEval, and Haystack metrics to assess performance and effectiveness.
\index{module@\spxentry{module}!tools.pipeline@\spxentry{tools.pipeline}}\index{tools.pipeline@\spxentry{tools.pipeline}!module@\spxentry{module}}\index{deepeval\_evaluate\_data() (in module tools.pipeline)@\spxentry{deepeval\_evaluate\_data()}\spxextra{in module tools.pipeline}}\phantomsection\label{\detokenize{evaluation:module-tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{evaluation:tools.pipeline.deepeval_evaluate_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{deepeval\_evaluate\_data}}}{\sphinxparam{\DUrole{n}{deepeval\_data}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{List\DUrole{p}{{[}}LLMTestCase\DUrole{p}{{]}}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ground\_truth}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{bool}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{True}}\sphinxparamcomma \sphinxparam{\DUrole{n}{model}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}gpt\sphinxhyphen{}4\textquotesingle{}}}}{{ $\rightarrow$ None}}
\pysigstopsignatures
\sphinxAtStartPar
Evaluates a prepared dataset using a suite of DeepEval’s metrics designed to assess the performance of language models. 
It outputs a structured report summarizing the results of each metric evaluation based on whether ground truth is considered.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{deepeval\_data}} \textendash{} The dataset containing test cases prepared for evaluation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ground\_truth}} \textendash{} Specifies whether metrics that require ground truth data should be included.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model}} \textendash{} The name of the model to be used for evaluation, defaults to “gpt\sphinxhyphen{}4”.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Outputs a structured report summarizing the metric evaluations.

\end{description}\end{quote}

\end{fulllineitems}

\index{deepeval\_prepare\_data() (in module tools.pipeline)@\spxentry{deepeval\_prepare\_data()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{evaluation:tools.pipeline.deepeval_prepare_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{deepeval\_prepare\_data}}}{\sphinxparam{\DUrole{n}{dataset}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{DataFrame}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ground\_truth}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{bool}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{True}}}{{ $\rightarrow$ List\DUrole{p}{{[}}LLMTestCase\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Prepares a dataset for using DeepEval evaluation metrics by creating test cases for each entry in the dataset. 
Each test case is structured to include a question, the actual and expected answers (if ground truth is provided),
and the retrieval context.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dataset}} \textendash{} The dataset to be prepared, typically containing ‘question’, ‘answer’, and ‘contexts’ columns,
and optionally a ‘ground\_truth’ column if ground\_truth is True.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ground\_truth}} \textendash{} Specifies whether the ‘ground\_truth’ column should be included in the test cases.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A list of test cases, each designed for evaluation purposes.

\end{description}\end{quote}

\end{fulllineitems}

\index{evaluate\_retriever() (in module tools.pipeline)@\spxentry{evaluate\_retriever()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{evaluation:tools.pipeline.evaluate_retriever}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{evaluate\_retriever}}}{\sphinxparam{\DUrole{n}{topic}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{vectorstore}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{Chroma}}\sphinxparamcomma \sphinxparam{\DUrole{n}{k}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{int}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{10}}}{{ $\rightarrow$ DataFrame}}
\pysigstopsignatures
\sphinxAtStartPar
Evaluates the performance of a vector store’s retrieval capabilities by conducting searches using
both cosine similarity and cosine distance metrics, and then compares the results.

\sphinxAtStartPar
This function retrieves the top ‘k’ documents based on the cosine similarity and cosine distance
metrics for a given topic. It constructs a DataFrame containing the results, including each
document’s ID, URL, context, similarity score, and distance score.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{topic}} \textendash{} The topic string based on which the documents are retrieved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{vectorstore}} \textendash{} An instance of a vector store configured with embeddings used for retrieving documents.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{k}} \textendash{} The number of top documents to retrieve, defaults to 10.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A pandas DataFrame containing the document details and their respective retrieval scores.

\end{description}\end{quote}

\end{fulllineitems}

\index{haystack\_evaluate\_data() (in module tools.pipeline)@\spxentry{haystack\_evaluate\_data()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{evaluation:tools.pipeline.haystack_evaluate_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{haystack\_evaluate\_data}}}{\sphinxparam{\DUrole{n}{data}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{List\DUrole{p}{{[}}Dict\DUrole{p}{{[}}str\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}\DUrole{p}{{]}}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ground\_truth}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{bool}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{True}}}{{ $\rightarrow$ DataFrame}}
\pysigstopsignatures
\sphinxAtStartPar
Evaluates the prepared dataset by running it through a series of Haystack’s evaluation metrics within a
pipeline. Metrics include context relevance, faithfulness of the answers, and optionally
semantic answer similarity if ground\_truth is True.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data}} \textendash{} A list of dictionaries where each dictionary contains ‘questions’, ‘contexts’,
‘predicted\_answers’, and optionally ‘ground\_truth\_answers’ if ground\_truth is True.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ground\_truth}} \textendash{} A flag to determine whether semantic similarity evaluation should be
performed using the ground truth answers provided in the data.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A pandas DataFrame containing the evaluation results for each data point, including scores
for context relevance, faithfulness, and optionally semantic similarity along with the overall
scores for these metrics.

\end{description}\end{quote}

\end{fulllineitems}

\index{haystack\_prepare\_data() (in module tools.pipeline)@\spxentry{haystack\_prepare\_data()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{evaluation:tools.pipeline.haystack_prepare_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{haystack\_prepare\_data}}}{\sphinxparam{\DUrole{n}{dataset}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{DataFrame}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ground\_truth}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{bool}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{True}}}{{ $\rightarrow$ List\DUrole{p}{{[}}Dict\DUrole{p}{{[}}str\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Prepares a dataset for using Haystack’s evaluation metrics by formatting the input data into a
specific structure.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dataset}} \textendash{} The dataset to be prepared, typically containing ‘question’, ‘answer’, and ‘contexts’ columns,
and optionally a ‘ground\_truth’ column if ground\_truth is True.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ground\_truth}} \textendash{} Specifies whether metrics that require ground truth data should be included.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A list of dictionaries, each containing data for a single instance. Each dictionary includes
the question, predicted answers, and context(s). If \sphinxtitleref{ground\_truth} is True, it also includes
ground truth answers.

\end{description}\end{quote}

\end{fulllineitems}

\index{ragas\_evaluate\_data() (in module tools.pipeline)@\spxentry{ragas\_evaluate\_data()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{evaluation:tools.pipeline.ragas_evaluate_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{ragas\_evaluate\_data}}}{\sphinxparam{\DUrole{n}{data}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{Dataset}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ChatOpenAI\_model\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}gpt\sphinxhyphen{}4\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{temperature}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{float}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ground\_truth}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{bool}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{True}}}{{ $\rightarrow$ Dict\DUrole{p}{{[}}str\DUrole{p}{,}\DUrole{w}{ }Any\DUrole{p}{{]}}}}
\pysigstopsignatures
\sphinxAtStartPar
Evaluates the prepared dataset using various evaluadtion metrics with a specified ChatGPT model as additional large language model.
It wraps the ChatGPT model in a LangchainLLMWrapper and calculates different metrics based on whether ground truth is considered.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data}} \textendash{} The prepared dataset to evaluate.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ChatOpenAI\_model\_name}} \textendash{} The model name of the ChatGPT to use for evaluation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temperature}} \textendash{} The sampling temperature to use in the model inference, defaults to 0.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ground\_truth}} \textendash{} Specifies whether metrics that require ground truth data should be included.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The evaluation results with specified metrics.

\end{description}\end{quote}

\end{fulllineitems}

\index{ragas\_prepare\_data() (in module tools.pipeline)@\spxentry{ragas\_prepare\_data()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{evaluation:tools.pipeline.ragas_prepare_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{ragas\_prepare\_data}}}{\sphinxparam{\DUrole{n}{dataset}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{DataFrame}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ground\_truth}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{bool}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{True}}}{{ $\rightarrow$ Dataset}}
\pysigstopsignatures
\sphinxAtStartPar
Prepares a dataset for use of the Ragas evaluation metrics by transforming
and ensuring proper formatting of its columns. This function resets the dataset index, ensures
‘contexts’ are lists of strings, optionally adds a ‘ground\_truth’ field, removes unnecessary
columns, and casts the dataset to specified features.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dataset}} \textendash{} The dataset to prepare, which should contain at least the ‘question’, ‘answer’, ‘contexts’ and ‘source’ field.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ground\_truth}} \textendash{} If True, includes the ‘ground\_truth’ field in the final dataset.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The transformed dataset with the specified features format.

\sphinxlineitem{Raises}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} If the data type of the ‘contexts’ field is neither a string nor a list.

\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Utils}
\label{\detokenize{utils:utils}}\label{\detokenize{utils::doc}}
\sphinxAtStartPar
This section includes various utility functions that support the operation and management of the RAG pipeline.
\index{module@\spxentry{module}!tools.pipeline@\spxentry{tools.pipeline}}\index{tools.pipeline@\spxentry{tools.pipeline}!module@\spxentry{module}}\index{load\_qa\_pairs() (in module tools.pipeline)@\spxentry{load\_qa\_pairs()}\spxextra{in module tools.pipeline}}\phantomsection\label{\detokenize{utils:module-tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils:tools.pipeline.load_qa_pairs}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{load\_qa\_pairs}}}{\sphinxparam{\DUrole{n}{folder\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{topic}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pipeline\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{content}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}generated\_qas\_gt\textquotesingle{}}}}{{ $\rightarrow$ DataFrame}}
\pysigstopsignatures
\sphinxAtStartPar
Loads question\sphinxhyphen{}answer pairs from a CSV file into a pandas DataFrame. The CSV file must be
named according to a specific naming convention and located in the specified folder.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{folder\_name}} \textendash{} The folder where the CSV file is stored.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{topic}} \textendash{} The main topic of the question\sphinxhyphen{}answer pairs, used in the file name.
The spaces in the topic will be replaced with underscores and converted to lowercase.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pipeline\_name}} \textendash{} The name of the pipeline used to generate the question\sphinxhyphen{}answer pairs,
used in the file name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{content}} \textendash{} An optional descriptor for the file name, defaults to ‘generated\_qas\_gt’.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A pandas DataFrame containing the loaded question\sphinxhyphen{}answer pairs. The ‘contexts’ column
is processed to remove square brackets and single quotes.

\end{description}\end{quote}

\end{fulllineitems}

\index{prepare\_dataset() (in module tools.pipeline)@\spxentry{prepare\_dataset()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils:tools.pipeline.prepare_dataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{prepare\_dataset}}}{\sphinxparam{\DUrole{n}{flashcard\_set}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}}{{ $\rightarrow$ Dataset}}
\pysigstopsignatures
\sphinxAtStartPar
Converts a JSON string of flashcard data into a structured dataset.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{flashcard\_set}} \textendash{} A JSON string that represents a set of flashcards. Each flashcard is a dictionary
with keys ‘question’, ‘answer’, ‘context’, and ‘source’.

\sphinxlineitem{Returns}
\sphinxAtStartPar
A dataset object with structured fields for questions, answers, contexts, and sources. The dataset
has features defined for each field to ensure correct data types.

\end{description}\end{quote}

\end{fulllineitems}

\index{save\_qa\_pairs() (in module tools.pipeline)@\spxentry{save\_qa\_pairs()}\spxextra{in module tools.pipeline}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils:tools.pipeline.save_qa_pairs}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{tools.pipeline.}}\sphinxbfcode{\sphinxupquote{save\_qa\_pairs}}}{\sphinxparam{\DUrole{n}{dataset}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{Any}}\sphinxparamcomma \sphinxparam{\DUrole{n}{folder\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{topic}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pipeline\_name}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}}\sphinxparamcomma \sphinxparam{\DUrole{n}{content}\DUrole{p}{:}\DUrole{w}{ }\DUrole{n}{str}\DUrole{w}{ }\DUrole{o}{=}\DUrole{w}{ }\DUrole{default_value}{\textquotesingle{}generated\_qas\textquotesingle{}}}}{{ $\rightarrow$ None}}
\pysigstopsignatures
\sphinxAtStartPar
Saves the provided dataset as a CSV file formatted for question\sphinxhyphen{}answer pairs,
organized by topic, pipeline name and content.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dataset}} \textendash{} The dataset containing the question\sphinxhyphen{}answer pairs. It can be a pandas DataFrame
or any object that has a \sphinxtitleref{to\_pandas()} method.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{folder\_name}} \textendash{} The name of the folder where the CSV file will be saved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{topic}} \textendash{} The main topic of the question\sphinxhyphen{}answer pairs, used in the file name.
The spaces in the topic will be replaced with underscores and converted to lowercase.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pipeline\_name}} \textendash{} The name of the pipeline used to generate the question\sphinxhyphen{}answer pairs.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{content}} \textendash{} An optional descriptor that precedes the file naming convention.
Defaults to ‘generated\_qas’.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\sphinxlineitem{Raises}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Exception}} \textendash{} If the dataset cannot be converted to a pandas DataFrame.

\end{description}\end{quote}

\sphinxAtStartPar
Upon successful saving of the file, this function prints “File saved as CSV.” to the standard output.
The file is saved with a semicolon as the delimiter and commas as the decimal separator.

\end{fulllineitems}



\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{t}
\item\relax\sphinxstyleindexentry{tools.pipeline}\sphinxstyleindexpageref{utils:\detokenize{module-tools.pipeline}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}